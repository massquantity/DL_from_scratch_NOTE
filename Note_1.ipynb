{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 感知器公式\n",
    "\n",
    "![](https://raw.githubusercontent.com/massquantity/DL_from_scratch_NOTE/master/pic/1.png)\n",
    "\n",
    "<font size=2> \n",
    "    b 是被称为偏置的参数,用于控制神经元被激活的容易程度; 而 w1 和 w2是表示各个信号的权重的参数,用于控制各个信号的重要性。</font>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)  # 不用 np.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3层神经网络的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/massquantity/DL_from_scratch_NOTE/master/pic/ch03_1.png)\n",
    "![](https://raw.githubusercontent.com/massquantity/DL_from_scratch_NOTE/master/pic/ch03_2.png)\n",
    "![](https://raw.githubusercontent.com/massquantity/DL_from_scratch_NOTE/master/pic/ch03_3.png)\n",
    "![](https://raw.githubusercontent.com/massquantity/DL_from_scratch_NOTE/master/pic/ch03_4.png)\n",
    "![](https://raw.githubusercontent.com/massquantity/DL_from_scratch_NOTE/master/pic/ch03_5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    network = dict()\n",
    "    network['W1'] = np.random.randn(2, 3)\n",
    "    network['b1'] = np.random.randn(3)\n",
    "    network['W2'] = np.random.randn(2, 3)\n",
    "    network['b2'] = np.random.randn(2)\n",
    "    network['W3'] = np.random.randn(2, 2)\n",
    "    network['b3'] = np.random.randn(2)\n",
    "    return network\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "    \n",
    "    z1 = np.dot(x, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    y = softmax(z3)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现 softmax 函数时的注意事项\n",
    "<br>\n",
    "\n",
    "<font size=2> \n",
    "    一般的 `softmax` 实现在计算机的运算上有一定的缺陷。这个缺陷就是溢出问题。`softmax` 函数的实现中要进行指\n",
    "数函数的运算,但是此时指数函数的值很容易变得非常大。比如,$e^{10}$ 的值\n",
    "会超过 20000,  $e^{100}$ 会变成一个后面有 40 多个 0 的超大值,$e^{1000}$ 的结果会返回\n",
    "一个表示无穷大的 `inf`。如果在这些超大值之间进行除法运算,结果会出现“不确定”的情况，所以通常减去最大值 \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    y = exp_a / np.sum(exp_a)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/usr/lib/spark/spark-2.3.2-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip',\n",
       " '/usr/lib/spark/spark-2.3.2-bin-hadoop2.7/python',\n",
       " '/home/massquantity/Workspace/DL_from_scratch/NOTE',\n",
       " '/home/massquantity/.conda/envs/py35/lib/python35.zip',\n",
       " '/home/massquantity/.conda/envs/py35/lib/python3.5',\n",
       " '/home/massquantity/.conda/envs/py35/lib/python3.5/plat-linux',\n",
       " '/home/massquantity/.conda/envs/py35/lib/python3.5/lib-dynload',\n",
       " '/home/massquantity/.conda/envs/py35/lib/python3.5/site-packages',\n",
       " '/home/massquantity/.conda/envs/py35/lib/python3.5/site-packages/python_recsys-0.2-py3.5.egg',\n",
       " '/home/massquantity/.conda/envs/py35/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/home/massquantity/.ipython',\n",
       " '..']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/massquantity/Workspace/DL_from_scratch/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0].reshape(28, 28) # 将 flatten 后的数据 reshape 为 28*28\n",
    "label = t_train[0]\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "& E = -\\sum\\limits_k t_k \\text{log}y_k \\\\\n",
    "& E = -\\frac{1}{N} \\sum\\limits_n \\sum\\limits_k t_{nk} \\text{log} y_{nk}  \\qquad \\text{(batch version)}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):  # y, t 均为 one-hot 形式\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(y * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):  # t 为标签形式 e.g. t = [1,4,8,...], y 为 one-hot\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    if t.size == y.size:   # 若 y 和 t 均为 one-hot， t转为标签\n",
    "        t = t.argmax(axis=1)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size \n",
    "    # y[np.arange(batch_size), t]， batch 中每个样本对应的 t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_2d(f, X):\n",
    "    grad = np.zeros_like(X)\n",
    "    h = 1e-4\n",
    "    for idx, x in enumerate(X):\n",
    "        for idx_2 in range(x.size):\n",
    "            temp = x[idx_2]\n",
    "            x[idx_2] = temp + h\n",
    "            fxh1 = f(x)\n",
    "            \n",
    "            x[idx_2] = temp - h\n",
    "            fxh2 = f(x)\n",
    "            grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "            x[idx_2] = temp\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numerical_gradient_1d(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 还原值\n",
    "        \n",
    "    return grad\n",
    "\n",
    "\n",
    "def numerical_gradient_2d(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return _numerical_gradient_1d(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = _numerical_gradient_1d(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0] ** 2 + x[1] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 4.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([[3.0, 4.0], [3.0, 4.0]])\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18., 32.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_2(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 8.],\n",
       "       [6., 8.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient_2d(function_2, aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
